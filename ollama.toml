# Config for a local ollama installation
#

[config]
# API type ('openai', 'google', ...)
api = 'ollama'

# Name of the model to use ('llama2', 'gemma:2b', ...)
name = "gemma3:1b"

# command-line prefix for launching process
cmd_prefix = "ollama run "
